 % use the "wcp" class option for workshop and conference
 % proceedings
 %\documentclass[gray]{jmlr} % test grayscale version
 %\documentclass[tablecaption=bottom]{jmlr}% journal article
 \documentclass[tablecaption=bottom,wcp]{jmlr} % W&CP article

 % The following packages will be automatically loaded:
 % amsmath, amssymb, natbib, graphicx, url, algorithm2e

 %\usepackage{rotating}% for sideways figures and tables
 %\usepackage{longtable}% for long tables

 % The booktabs package is used by this sample document
 % (it provides \toprule, \midrule and \bottomrule).
 % Remove the next line if you don't require it.
\usepackage{booktabs}
 % The siunitx package is used by this sample document
 % to align numbers in a column by their decimal point.
 % Remove the next line if you don't require it.
\usepackage[load-configurations=version-1]{siunitx} % newer version
 %\usepackage{siunitx}

 % The following command is just for this sample document:
\newcommand{\cs}[1]{\texttt{\char`\\#1}}% remove this in your real article

 % Define an unnumbered theorem just for this sample document for
 % illustrative purposes:
\theorembodyfont{\upshape}
\theoremheaderfont{\scshape}
\theorempostheader{:}
\theoremsep{\newline}
\newtheorem*{note}{Note}

 % change the arguments, as appropriate, in the following:
\jmlrvolume{1}
\jmlryear{20XX}
\jmlrsubmitted{submission date}
\jmlrpublished{publication date}
\jmlrworkshop{workshop title} % W&CP title

 % The optional argument of \title is used in the header
\title[SUNNY-OASC]{SUNNY with Algorithm Configuration}


 % Two authors with the same address
  \author{\Name{Tong Liu} \Email{t.liu@unibo.it}\\
   \Name{Roberto Amadini} \Email{roberto.amadini@unimelb.edu.au}\\
   \Name{Jacopo Mauro} \Email{mauro.jacopo@gmail.com}\\
    }



 % Authors with different addresses:
 % \author{\Name{Author Name1} \Email{abc@sample.com}\\
 % \addr Address 1
 % \AND
 % \Name{Author Name2} \Email{xyz@sample.com}\\
 % \addr Address 2
 %}


 %\editors{Editor One and Editor Two}% for multiple editors

\begin{document}

\maketitle



\section{Description}

\subsection{Proposals}
This proposed solution is an improvement of SUNNY-AS \cite{DBLP:conf/cilc/AmadiniBGLM15,sunnyas} with the ideas suggested by the Works \cite{DBLP:conf/lion/LindauerBH16,Kohavi97wrappersfor}.

SUNNY-AS is an per instance algorithm scheduling strategy based on K-NN techniques. The Work \cite{DBLP:conf/lion/LindauerBH16} has demonstrated that how a training phase, by studying the value $K$ and the number of solvers, can boost SUNNY performance. However, we believe that the number of solvers is a trivial option to configure, because, in our original version, SUNNY employs less solvers as reported by \cite{DBLP:conf/lion/LindauerBH16}. In this Work, we have proposed two solutions, `autok' and `fkvar'. 

\begin{itemize}
  \item The `autok' has borrowed the ideas of TSUNNY from \cite{DBLP:conf/lion/LindauerBH16} by considering only the value $K$ (ignoring the number of solvers). 
  \item The `fkvar' instead trains for both value $K$ and optimal features by using a wrapper method \cite{Kohavi97wrappersfor}, that is, we take SUNNY as the evaluator to measure the importance of each feature, we then perform a greedy forward selection, which consists several selection cycles. In each cycle, we loop on unselected feature set, we pick one feature at time and combine it with selected features (initially empty) as a test feature set. By tuning also the value k, SUNNY calculates the best par10 score that it can achieve with the test feature set. In the end of each cycle, it incorporates a new feature to the selected feature set. We stop further selection cycle when adding the new test feature alters SUNNY performance or the number of feature limit (cycle) is reached. At last, `fkvar' produces a combination of features and value $K$ which SUNNY performs the best on training data.
\end{itemize}
 

\subsection{Representative instances}
The representative instances are selected by the following way, it first classifies each instance to a solver who solve it in least time, then for each solver (class), it orders the instances from hard to easy in terms of runtime, then for each class, it picks one instance a time in order to reach the instance limit. 

\subsection{Parameters}
Our previous experiments \cite{DBLP:conf/cilc/AmadiniBGLM15} suggested that a handful subset of features (eg: 5) is often enough for SUNNY to obtain a competitive performance, as such, in `fkvar' we fixed such amount of feature to select. In order to guarantee an acceptable execution runtime, for the `fkvar' approach, we have taken up to $1500$ representative instances from training set as effective instances, and we also fixed the interval of $K$ as [3,30] \footnote{Several scenarios with around 5.000 instances, it may take couple of days for training. Besides, the interval [3,30] would cover most of the useful K values. }.  In the end of execution, we re-run `autok' $K \in [3,80]$ for a backup, i.e. if SUNNY runs better with entire features, we then adopt the combination of $K$ with the whole feature set instead. Differently, in the `autok' version, we consider the full training set as effective training data.

\section{Setup Instruction}

The source code is available at \cite{sunnyoasc} which requires Python v2.x. There are five folders, `data' and `results' contain oasc-challenge data and solution results respectively. `src' contains the original SUNNY-AS scripts from \cite{sunnyas}, `oasc' contains scripts who coordinate those in `src' for training and testing. In the end, in the folder `main', there have been placed the scripts that automatically call scripts in `oasc' for different scenarios. 

The program runs training and testing in sequence, let us take `autok' approach as execution example. In the folder `main', launch the command ``sh make\_oasc\_tasks.sh $<$ tasks.txt'' to create tasks. Then train scenarios with ``sh oasc\_train.sh run\_autok tasks.txt''. After training, run testing with command ``sh make\_oasc\_tasks.sh $<$ tasks.txt'' then, ``sh oasc\_test.sh autok tasks.txt''. Whereas, to run fkvar approach, it is sufficient to replace literally `autok' by `fkvar' in the previous commands. 

\bibliography{reference}

\appendix

\end{document}
